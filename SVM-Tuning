# -*- coding: utf-8 -*-
"""
Created on Tue Nov  3 11:29:36 2020

@author: andyt
"""



from sklearn import svm
import numpy as np
import pandas as pd 

dataset = pd.read_csv("rao_hmec_10kb.tads.boundary.4mer.features.csv")

 
# Load dataset

from sklearn.preprocessing import LabelEncoder
 
X = dataset.iloc[:, 1:-1].values
y = dataset.iloc[:, -1].values
le = LabelEncoder()
y = le.fit_transform(y)
le.transform([0,1])


# set dataset into 80% training and 20% testing

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state= 1)


#build SVM model, non-linear, kernel = rbf
from sklearn.svm import SVC 
nonlinear_clf =svm.SVC()
nonlinear_clf.fit(X_train, y_train)
y_pred = nonlinear_clf.predict(X_test)


from sklearn.metrics import classification_report, confusion_matrix


from sklearn.model_selection import GridSearchCV 
  
# defining parameter range 
param_grid = {'C': [0.001, 0.01, 0.1, 1, 10],
              'gamma': [1], 
              'kernel': ['rbf']}  
  
grid = GridSearchCV( svm.SVC(), param_grid, refit=True,cv=10 , verbose=2, n_jobs=-1)
# fitting the model for grid search 
grid.fit(X_train, y_train) 

# print  parameter before tuning 

print(" Before Tuning")
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))


print("----------------------------------")
print("After Tuning")

# print best parameter after tuning 
print(grid.best_params_) 
  
# print how our model looks after hyper-parameter tuning 
print(grid.best_estimator_) 

grid_predictions = grid.predict(X_test) 

  
# print classification report 
print(classification_report(y_test, grid_predictions)) 



print("-------------------------------------------")

# save the model to disk
import pickle 
filename = 'SVM.pickle'
pickle.dump(grid, open(filename, 'wb'))
 
 

# load the model from disk
loaded_model = pickle.load(open(filename, 'rb'))#result = loaded_model.score(X_test, y_test)
print(classification_report(y_test, grid_predictions))
